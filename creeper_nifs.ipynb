{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file is class designed for doing data mining for a given specied in NIFS database.Befroe the main functions conducting, I define two classes to help.\n",
    "<p> Firstly, I define a function to define process, as QBD cannot be judged directly from the original process.\n",
    "<p> Secondly, I define a function to connect website process with QDB process. \n",
    "Then, in the main functions:\n",
    "<p> Firstly, for a given specie, I retrieve all basic information for each record number, including reference information, reaction formula, process, sub process, states and so on.\n",
    "<p> Then, for a given record number, I retrieve all the meta data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.stem import PorterStemmer \n",
    "from selenium import webdriver\n",
    "from time import sleep\n",
    "import sys\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class creep_species_nifs:\n",
    "    \n",
    "    def __init__(self,specie):\n",
    "        self.specie = specie\n",
    "        self.data_list = {}\n",
    "        \n",
    "    # Define a function to do pre-processing for procss.\n",
    "    def define_process(self,process):\n",
    "        if re.search(\";\",process) != None: # If there is \";\",  the process contains multi processes.\n",
    "            process = re.sub(\"[;]\",\" \",process)\n",
    "            process_list = re.split(\" \",process) # Split the process into single word for the purpose of connecting QDB process.\n",
    "        else:\n",
    "            process_list = re.split(\" \",process) # Split the process into single word for the purpose of connecting QDB process.\n",
    "        return process_list\n",
    "    \n",
    "    # Define a function to connect website process wtih QDB process.\n",
    "    def QDB_process(self,process_list):\n",
    "        \n",
    "        ## Set it empty in case there is no related QDB process.\n",
    "        abbreviation = \"\"\n",
    "        \n",
    "        ## Judge whether there is a related QDB process, if there is, reset the value of \"QDB\".\n",
    "        if \"deexcitation\" in process_list:\n",
    "            abbreviation = \"EDX\"\n",
    "            \n",
    "        if (\"elastic\" in process_list) and (\"scattering\" in process_list):\n",
    "            abbreviation = \"EEL\"\n",
    "            \n",
    "        if \"ionization\" in process_list:\n",
    "            if \"dissociative\" in process_list:\n",
    "                abbreviation = \"EDI\"\n",
    "            elif (\"electron\" in process_list) and (\"total\" in process_list):\n",
    "                abbreviation = \"ETI\"\n",
    "            else:\n",
    "                abbreviation = \"EIN\"\n",
    "                \n",
    "        if \"dissociation\" in process_list:\n",
    "            abbreviation = \"EDS\"\n",
    "        \n",
    "        if \"recombination\" in process_list:\n",
    "            if \"radiative\" in process_list:\n",
    "                abbreviation = \"ERR\"\n",
    "            elif \"dissociative\" in process_list:\n",
    "                abbreviation = \"EDR\"\n",
    "            else:\n",
    "                abbreviation = \"ERC\"\n",
    "                \n",
    "        if (\"momentum\" in process_list) and (\"transfer\" in process_list):\n",
    "            abbreviation = \"EMT\"\n",
    "\n",
    "        if \"attachment\" in process_list:\n",
    "            if \"dissociative\" in process_list:\n",
    "                abbreviation = \"EDA\"\n",
    "            elif \"electron\" in process_list:\n",
    "                if \"total\" in process_list:\n",
    "                    abbreviation = \"ETA\"\n",
    "                else:\n",
    "                    abbreviation = \"EDT\"\n",
    "                    \n",
    "        if (\"total\" in process_list) and (\"scattering\" in process_list):\n",
    "            abbreviation = \"ETS\"\n",
    "\n",
    "\n",
    "        if \"excitation\" in process_list:\n",
    "            if \"dissociative\" in process_list:\n",
    "                abbreviation = \"EDE\"\n",
    "            elif \"electronic\" in process_list:\n",
    "                    abbreviation = \"EEX\"\n",
    "            elif \"vibrational\" in process_list:\n",
    "                    abbreviation = \"EVX\"\n",
    "            else:\n",
    "                abbreviation = \"ECX\"\n",
    "           \n",
    "        return abbreviation\n",
    "    \n",
    "    # Define a function to extract basic information for a given specie.\n",
    "    def extract_basic_information(self):\n",
    "        \n",
    "        ## Search for the given specie.\n",
    "        driver = webdriver.Chrome()\n",
    "        driver.get(\"http://dbshino.nifs.ac.jp/nifsdb/nifs_db/select\")\n",
    "        driver.find_element_by_xpath(\"/html/body/h2[2]/ul/a[5]\").click()\n",
    "        sleep(5) # In case I don't get into the website\n",
    "        driver.find_element_by_xpath(\"/html/body/form/ul[1]/table[1]/tbody/tr[1]/td[3]/input\").send_keys(self.specie) # Enter the specie.\n",
    "        driver.find_element_by_id(\"btn_search\").click() \n",
    "\n",
    "        # Click the boxes to display and extract basic information later.\n",
    "        if len(driver.find_elements_by_id(\"display_format_custom\")) != 0:\n",
    "            driver.find_element_by_id(\"display_format_custom\").click()\n",
    "            for i in range (7):\n",
    "                if i != 5:\n",
    "                    for j in range (4):\n",
    "                        if (i==0 and j!=3) or (i==1 and j!=1) or (i==2 and j!=3) or (i==3 and j!=0) or (i==6 and j<2) or i==4:\n",
    "                            x_path = \"/html/body/form/ul[2]/table/tbody/tr[\"\\\n",
    "                                     + str(i + 1) + \"]/td[\" + str(j + 1)+\"]/input[2]\"\n",
    "                            driver.find_element_by_xpath(x_path).click()\n",
    "            driver.find_element_by_id(\"btn_find_display\").click()\n",
    "\n",
    "            # Extract basic information\n",
    "            cout = len(driver.find_elements_by_xpath(\"//body/form/ul\"))\n",
    "            specie = []\n",
    "            record_number = []\n",
    "            process = []\n",
    "            QDB = []\n",
    "            type_name = []\n",
    "            element = []\n",
    "            ionic_state = []\n",
    "            initial_state_conf = []\n",
    "            initial_state = []\n",
    "            final_state = []\n",
    "            reaction_formula = []\n",
    "            reference_number = []\n",
    "            author = []\n",
    "            title_of_record = []\n",
    "            journal_name = []\n",
    "            volume_and_issue_No = []\n",
    "            page_number = []\n",
    "            data_of_publication = []\n",
    "            x_unit = []\n",
    "            y_unit = []\n",
    "\n",
    "            for k in range (cout):\n",
    "\n",
    "                ## Extract basic information and splitting it to classify them.\n",
    "                text_xpath = \"/html/body/form/ul[\"+str(k+1)+\"]\" # Find whole information location\n",
    "                text = driver.find_element_by_xpath(text_xpath).text # Extract the information.\n",
    "                text_split = re.split('[\\n]',text) # Split text through \"enter\"\n",
    "                len_text = len(text_split)\n",
    "                result_text = []\n",
    "                 \n",
    "                # Split text through \"=\" to get value for each attribute\n",
    "                for a in range (len_text):\n",
    "                    locate = re.search('[=]',text_split[a]).span()[1]\n",
    "                    result_text.append(text_split[a][locate:]) \n",
    "\n",
    "                # Define specie through charge.\n",
    "                text_element = result_text[3].strip()\n",
    "                if text_element==self.specie:\n",
    "                    if result_text[4].strip()=='1': # The specie is with positive charge.\n",
    "                        specie.append(self.specie+\"+\")\n",
    "                    if result_text[4].strip()=='-1': # The specie is with nagetive charge.\n",
    "                        specie.append(self.specie+\"-\")\n",
    "                    if result_text[4].strip()=='0': # The specie is without charge.\n",
    "                        specie.append(self.specie)\n",
    "                    \n",
    "                    # Memorize record number and process.\n",
    "                    record_number.append(result_text[0].strip())\n",
    "                    process.append(re.sub(\"[;]\",\" \",result_text[1].strip()))\n",
    "                    \n",
    "                    # Split process and then define QDB process\n",
    "                    process_list = self.define_process(result_text[1].strip())\n",
    "                    QDB.append(self.QDB_process(process_list))\n",
    "                    \n",
    "                    # Memorize basic information\n",
    "                    type_name.append(result_text[2])\n",
    "                    element.append(result_text[3])\n",
    "                    ionic_state.append(result_text[4])\n",
    "                    initial_state_conf.append(result_text[5])\n",
    "                    initial_state.append(result_text[6])\n",
    "                    final_state.append(re.sub(\"[;]\",\"+\",result_text[7])) # Replace \";\" with \"+\" to make the products in one column.\n",
    "                    reaction_formula.append(result_text[8])\n",
    "                    reference_number.append(\"RN\"+result_text[9]) # Add \"RN\" in case of the mathematic formation of \"E\"\n",
    "                    author.append(re.sub(\"[,$]\",\" \",result_text[10])) # Replace \",\" and \"$\" to make the author in one column.\n",
    "                    title_of_record.append(result_text[11])\n",
    "                    journal_name.append(result_text[12])\n",
    "                    volume_and_issue_No.append(result_text[13])\n",
    "                    page_number.append(result_text[14])\n",
    "                    data_of_publication.append(result_text[15])\n",
    "                    x_unit.append(result_text[16])\n",
    "                    y_unit.append(result_text[17])\n",
    "                # Record basic information.\n",
    "                self.pd_specie = pd.DataFrame(data=[specie,record_number,process,QDB,type_name,\\\n",
    "                                                    element,ionic_state,initial_state_conf,\\\n",
    "                                                    initial_state,final_state,reaction_formula,\\\n",
    "                                                    x_unit,y_unit,reference_number,author,title_of_record,\\\n",
    "                                                    journal_name,volume_and_issue_No,\\\n",
    "                                                    page_number,data_of_publication],\\\n",
    "                                             index=['specie','record_number','process','QDB_process','type','element',\\\n",
    "                                                    'ionic_state','initial_state_conf','initial_state',\\\n",
    "                                                    'final_state','reaction_formula','x_unit','y_unit',\\\n",
    "                                                    'reference_number','author','title_of_record','journal_name',\\\n",
    "                                                    'volume_and_issue_No','page_number','date_of_publication']).T\n",
    "\n",
    "            # Close the website.\n",
    "            driver.close()\n",
    "        else:\n",
    "            # Close the website.\n",
    "            driver.close()  \n",
    "    \n",
    "    # Define a function to extract meta data.\n",
    "    def extract_data(self):\n",
    "        # Get into the website to get meta data for a given specie.\n",
    "        driver = webdriver.Chrome()\n",
    "        driver.get(\"http://dbshino.nifs.ac.jp/nifsdb/nifs_db/select\")\n",
    "        driver.find_element_by_xpath(\"/html/body/h2[2]/ul/a[5]\").click()\n",
    "        sleep(5) # In case I don't get into the website\n",
    "        driver.find_element_by_xpath(\"/html/body/form/ul[1]/table[1]/tbody/tr[1]/td[3]/input\").send_keys(self.specie) # Enter the specie.\n",
    "        driver.find_element_by_id(\"btn_search\").click()\n",
    "\n",
    "        # Click for meta data graph.\n",
    "        if len(driver.find_elements_by_id(\"display_format_numeric\")) != 0:\n",
    "            driver.find_element_by_id(\"display_format_numeric\").click()\n",
    "            driver.find_element_by_id(\"btn_find_display\").click() # Display the graph\n",
    "            sleep(5) # In case I don't get into the website\n",
    "            driver.find_element_by_id(\"display_write_vertical\").click()\n",
    "            driver.find_element_by_id(\"btn_num_display\").click() # Show all the meta data.\n",
    "\n",
    "            # Count the number of meta data for a given record number.\n",
    "            cout = len(driver.find_elements_by_xpath(\"//body/form/ul\"))\n",
    "            for i in range (cout):\n",
    "                text = driver.find_element_by_xpath(\"//body/form/ul[\"+str(i+1)+\"]\").text # Find record number location.\n",
    "                record_number = re.split('[\\n=]',text)[1]\n",
    "                if record_number in self.pd_specie[\"record_number\"].tolist(): # Only record meta data whose record number in list.\n",
    "                    # Extract meta data.\n",
    "                    X = []\n",
    "                    Y = []\n",
    "                    X_error = []\n",
    "                    Y_error = []\n",
    "                    data_xpath = \"/html/body/form/ul[\"+str(i+1)+\"]/ul/table/tbody/tr\" # Find meta data location.\n",
    "                    amount = len(driver.find_elements_by_xpath(data_xpath)) # Count the number of meta data.\n",
    "                    for k in range (amount):\n",
    "                        if k != 0: # The first piece is not meta data.\n",
    "                            x_path = \"/html/body/form/ul[\"+str(i+1)+\\\n",
    "                                     \"]/ul/table/tbody/tr[\"+str(k+1)+\"]/td[1]\"\n",
    "                            y_path = \"/html/body/form/ul[\"+str(i+1)+\\\n",
    "                                     \"]/ul/table/tbody/tr[\"+str(k+1)+\"]/td[2]\"\n",
    "                            y_error_path = \"/html/body/form/ul[\"+str(i+1)+\\\n",
    "                                     \"]/ul/table/tbody/tr[\"+str(k+1)+\"]/td[3]\"            \n",
    "                            y_error_minus_path = \"/html/body/form/ul[\"+str(i+1)+\\\n",
    "                                     \"]/ul/table/tbody/tr[\"+str(k+1)+\"]/td[4]\" \n",
    "\n",
    "                            x = driver.find_element_by_xpath(x_path).text\n",
    "                            y = driver.find_element_by_xpath(y_path).text\n",
    "                                         \n",
    "                            # Compute y error average which is the average value of y error minus and y error.\n",
    "                            y_error = driver.find_element_by_xpath(y_error_path).text\n",
    "                            y_error_minus = driver.find_element_by_xpath(y_error_minus_path).text\n",
    "                            y_error_average = (abs(float(y_error))+abs(float(y_error_minus)))/2\n",
    "                            x_error = 0 # This database doesn't include x error value, so I make it zero.\n",
    "\n",
    "                            X.append(x)\n",
    "                            Y.append(y)\n",
    "                            X_error.append(x_error)\n",
    "                            Y_error.append(y_error_average)\n",
    "\n",
    "                    # Memorize meta data dataframe.\n",
    "                    pd_data_1 = pd.DataFrame(data=[X,Y,X_error,Y_error],\\\n",
    "                                           index=['X','Y','X_error','Y_error']).T\n",
    "                    pd_data_1 = pd_data_1\n",
    "                    self.data_list[record_number] = pd_data_1.reindex(columns=['ID','X','Y','X_error','Y_error'],\\\n",
    "                                                                               fill_value=record_number\n",
    "                                                                 )\n",
    "            # Close the website.\n",
    "            driver.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}